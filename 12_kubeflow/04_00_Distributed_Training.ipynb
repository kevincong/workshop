{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Distributed Training\n",
    "Deep learning has shown that being able to train large models on vasts amount of data can drastically improve model performance. \n",
    "\n",
    "However, consider the problem of training a deep network with millions, or even billions of parameters. How do we achieve this without waiting for days, or even multiple weeks? Dean et al propose a different training paradigm which allows us to train and serve a model on multiple physical machines. The auth|ors propose two novel methodologies to accomplish this, namely, `model parallelism` and `data parallelism`.\n",
    "\n",
    "\n",
    "# Model Parallelism\n",
    "When a big model can not fit into a single node's memory, model parallel training can be employed to handle the big model. Model parallelism training has two key features:\n",
    "1. Each worker task is responsible for estimating different part of the model parameters. So the computation logic in each worker is different from other one else.\n",
    "2. There is application-level data communication between workers. \n",
    "\n",
    "![Model Parallelism](./images/model_parallelism.jpg)\n",
    "\n",
    "\n",
    "# Data Parallelism\n",
    "\n",
    "The algorithm distributes the data between various tasks.\n",
    "1. Each worker task is responsible for estimating different part of the dataset\n",
    "2. Tasks then exchange their estimate(s) with each other to come up with the right estimate for the step.\n",
    "\n",
    "![Data Parallelism](./images/data_parallelism.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Training in Tensorflow \n",
    "\"Data Parallelism\" is the most common training configuration, it involves multiple tasks in a `worker` job training the same model on different mini-batches of data, updating shared parameters hosted in one or more tasks in a `ps` (parameter server) job. All tasks typically run on different machines or containers. There are many ways to specify this structure in TensorFlow, and Tensorflow team are building libraries that will simplify the work of specifying a replicated model. Other platforms like `MXnet`, `Petuum` also have the same abstraction. \n",
    "\n",
    "- __In-graph replication__. In this approach, the client builds a single tf.Graph that contains one set of parameters (in tf.Variable nodes pinned to /job:ps); and multiple copies of the compute-intensive part of the model, each pinned to a different task in /job:worker.\n",
    "\n",
    "- __Between-graph replication__. In this approach, there is a separate client for each /job:worker task, typically in the same process as the worker task. Each client builds a similar graph containing the parameters (pinned to /job:ps as before using tf.train.replica_device_setter to map them deterministically to the same tasks); and a single copy of the compute-intensive part of the model, pinned to the local task in /job:worker.\n",
    "\n",
    "- __Asynchronous training__. In this approach, each replica of the graph has an independent training loop that executes without coordination. It is compatible with both forms of replication above.\n",
    "\n",
    "- __Synchronous training__. In this approach, all of the replicas read the same values for the current parameters, compute gradients in parallel, and then apply them together. It is compatible with in-graph replication (e.g. using gradient averaging as in the CIFAR-10 multi-GPU trainer), and between-graph replication (e.g. using the tf.train.SyncReplicasOptimizer).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "\n",
    "We will introduce two frameworks in the distributed training. Tensorflow and PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Distributed TensorFlow Job (TFJob) Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: \"kubeflow.org/v1\"\r\n",
      "kind: \"TFJob\"\r\n",
      "metadata:\r\n",
      "  name: \"distributed-tensorflow-job\"\r\n",
      "spec:\r\n",
      "  tfReplicaSpecs:\r\n",
      "    PS:\r\n",
      "      replicas: 2\r\n",
      "      restartPolicy: Never\r\n",
      "      template:\r\n",
      "        metadata:\r\n",
      "          annotations:\r\n",
      "            sidecar.istio.io/inject: \"false\"\r\n",
      "        spec:\r\n",
      "          containers:\r\n",
      "            - name: tensorflow\r\n",
      "              image: gcr.io/kubeflow-ci/tf-dist-mnist-test:1.0\r\n",
      "    Worker:\r\n",
      "      replicas: 4\r\n",
      "      restartPolicy: Never\r\n",
      "      template:\r\n",
      "        metadata:\r\n",
      "          annotations:\r\n",
      "            sidecar.istio.io/inject: \"false\"\r\n",
      "        spec:\r\n",
      "          containers:\r\n",
      "            - name: tensorflow\r\n",
      "              image: gcr.io/kubeflow-ci/tf-dist-mnist-test:1.0"
     ]
    }
   ],
   "source": [
    "!cat ./distributed-training-jobs/distributed-tensorflow-job.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch Distributed TensorFlow Training job (`TFJob`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfjob.kubeflow.org/distributed-tensorflow-job created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f distributed-training-jobs/distributed-tensorflow-job.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View All TFJobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                         STATE   AGE\r\n",
      "distributed-tensorflow-job           1s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get tfjob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check TFJob Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:         distributed-tensorflow-job\r\n",
      "Namespace:    anonymous\r\n",
      "Labels:       <none>\r\n",
      "Annotations:  <none>\r\n",
      "API Version:  kubeflow.org/v1\r\n",
      "Kind:         TFJob\r\n",
      "Metadata:\r\n",
      "  Creation Timestamp:  2020-08-23T00:18:28Z\r\n",
      "  Generation:          1\r\n",
      "  Resource Version:    79238\r\n",
      "  Self Link:           /apis/kubeflow.org/v1/namespaces/anonymous/tfjobs/distributed-tensorflow-job\r\n",
      "  UID:                 73174228-22ef-4236-a069-d4fc3ec36918\r\n",
      "Spec:\r\n",
      "  Tf Replica Specs:\r\n",
      "    PS:\r\n",
      "      Replicas:        2\r\n",
      "      Restart Policy:  Never\r\n",
      "      Template:\r\n",
      "        Metadata:\r\n",
      "          Annotations:\r\n",
      "            sidecar.istio.io/inject:  false\r\n",
      "        Spec:\r\n",
      "          Containers:\r\n",
      "            Image:  gcr.io/kubeflow-ci/tf-dist-mnist-test:1.0\r\n",
      "            Name:   tensorflow\r\n",
      "    Worker:\r\n",
      "      Replicas:        4\r\n",
      "      Restart Policy:  Never\r\n",
      "      Template:\r\n",
      "        Metadata:\r\n",
      "          Annotations:\r\n",
      "            sidecar.istio.io/inject:  false\r\n",
      "        Spec:\r\n",
      "          Containers:\r\n",
      "            Image:  gcr.io/kubeflow-ci/tf-dist-mnist-test:1.0\r\n",
      "            Name:   tensorflow\r\n",
      "Events:             <none>\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl describe tfjob distributed-tensorflow-job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Distributed TensorFlow Training Logs\n",
    "_Note:  If you see an error in this cell, just wait a bit and re-run to see the logs._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl get pod | grep distributed-tensorflow-job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (NotFound): pods \"distributed-tensorflow-job-worker-0\" not found\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl logs distributed-tensorflow-job-worker-0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch Distributed PyTorch Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: \"kubeflow.org/v1\"\r\n",
      "kind: \"PyTorchJob\"\r\n",
      "metadata:\r\n",
      "  name: \"distributed-pytorch-job\"\r\n",
      "spec:\r\n",
      "  pytorchReplicaSpecs:\r\n",
      "    Master:\r\n",
      "      replicas: 1\r\n",
      "      restartPolicy: OnFailure\r\n",
      "      template:\r\n",
      "        metadata:\r\n",
      "          annotations:\r\n",
      "            sidecar.istio.io/inject: \"false\"\r\n",
      "        spec:\r\n",
      "          containers:\r\n",
      "            - name: pytorch\r\n",
      "              image: gcr.io/kubeflow-ci/pytorch-dist-mnist_test:1.0\r\n",
      "              args: [\"--backend\", \"gloo\"]\r\n",
      "              # Comment out the below resources to use the CPU.\r\n",
      "              #resources:\r\n",
      "                #limits:\r\n",
      "                  #nvidia.com/gpu: 1\r\n",
      "    Worker:\r\n",
      "      replicas: 2\r\n",
      "      restartPolicy: OnFailure\r\n",
      "      template:\r\n",
      "        metadata:\r\n",
      "          annotations:\r\n",
      "            sidecar.istio.io/inject: \"false\"\r\n",
      "        spec:\r\n",
      "          containers:\r\n",
      "            - name: pytorch\r\n",
      "              image: gcr.io/kubeflow-ci/pytorch-dist-mnist_test:1.0\r\n",
      "              args: [\"--backend\", \"gloo\"]\r\n",
      "              # Comment out the below resources to use the CPU.\r\n",
      "              #resources:\r\n",
      "                #limits:\r\n",
      "                  #nvidia.com/gpu: 1\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat ./distributed-training-jobs/distributed-pytorch-job.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch Distributed PyTorch Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorchjob.kubeflow.org/distributed-pytorch-job created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f ./distributed-training-jobs/distributed-pytorch-job.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:         distributed-pytorch-job\r\n",
      "Namespace:    anonymous\r\n",
      "Labels:       <none>\r\n",
      "Annotations:  kubectl.kubernetes.io/last-applied-configuration:\r\n",
      "                {\"apiVersion\":\"kubeflow.org/v1\",\"kind\":\"PyTorchJob\",\"metadata\":{\"annotations\":{},\"name\":\"distributed-pytorch-job\",\"namespace\":\"anonymous\"}...\r\n",
      "API Version:  kubeflow.org/v1\r\n",
      "Kind:         PyTorchJob\r\n",
      "Metadata:\r\n",
      "  Creation Timestamp:  2020-08-23T00:18:33Z\r\n",
      "  Generation:          1\r\n",
      "  Resource Version:    79343\r\n",
      "  Self Link:           /apis/kubeflow.org/v1/namespaces/anonymous/pytorchjobs/distributed-pytorch-job\r\n",
      "  UID:                 7b088709-0bed-407e-a387-a11dbd8b4e7d\r\n",
      "Spec:\r\n",
      "  Pytorch Replica Specs:\r\n",
      "    Master:\r\n",
      "      Replicas:        1\r\n",
      "      Restart Policy:  OnFailure\r\n",
      "      Template:\r\n",
      "        Metadata:\r\n",
      "          Annotations:\r\n",
      "            sidecar.istio.io/inject:  false\r\n",
      "        Spec:\r\n",
      "          Containers:\r\n",
      "            Args:\r\n",
      "              --backend\r\n",
      "              gloo\r\n",
      "            Image:  gcr.io/kubeflow-ci/pytorch-dist-mnist_test:1.0\r\n",
      "            Name:   pytorch\r\n",
      "    Worker:\r\n",
      "      Replicas:        2\r\n",
      "      Restart Policy:  OnFailure\r\n",
      "      Template:\r\n",
      "        Metadata:\r\n",
      "          Annotations:\r\n",
      "            sidecar.istio.io/inject:  false\r\n",
      "        Spec:\r\n",
      "          Containers:\r\n",
      "            Args:\r\n",
      "              --backend\r\n",
      "              gloo\r\n",
      "            Image:  gcr.io/kubeflow-ci/pytorch-dist-mnist_test:1.0\r\n",
      "            Name:   pytorch\r\n",
      "Events:             <none>\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl describe pytorchjob distributed-pytorch-job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Distributed PyTorch Training Logs\n",
    "## _Note:  If you see an error below, just wait a bit and re-run.  You will eventually see the pod status change to `Running` or `Completed`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distributed-pytorch-job-worker-0      0/1     Init:0/1            0          0s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pod | grep distributed-pytorch-job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If You See an Error Below, Wait a Few Seconds and Re-Run It "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using distributed PyTorch with gloo backend\r\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\r\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\r\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\r\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\r\n",
      "Processing...\r\n",
      "Done!\r\n",
      "Train Epoch: 1 [0/60000 (0%)]\tloss=2.3000\r\n",
      "Train Epoch: 1 [640/60000 (1%)]\tloss=2.2135\r\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tloss=2.1704\r\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tloss=2.0766\r\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tloss=1.8679\r\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tloss=1.4135\r\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tloss=1.0003\r\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tloss=0.7762\r\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tloss=0.4598\r\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tloss=0.4860\r\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tloss=0.4389\r\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tloss=0.4084\r\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tloss=0.4602\r\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tloss=0.4289\r\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tloss=0.3990\r\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tloss=0.3852\r\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tloss=0.2984\r\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tloss=0.5029\r\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tloss=0.5236\r\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tloss=0.3378\r\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tloss=0.3674\r\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tloss=0.4508\r\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tloss=0.3034\r\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tloss=0.3575\r\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tloss=0.3313\r\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tloss=0.4405\r\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tloss=0.3639\r\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tloss=0.3169\r\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tloss=0.2014\r\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tloss=0.4976\r\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tloss=0.3257\r\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tloss=0.1192\r\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tloss=0.1902\r\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tloss=0.1412\r\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tloss=0.3140\r\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tloss=0.1515\r\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tloss=0.2892\r\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tloss=0.4668\r\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tloss=0.2153\r\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tloss=0.1508\r\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tloss=0.2245\r\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tloss=0.2629\r\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tloss=0.2330\r\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tloss=0.2619\r\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tloss=0.2126\r\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tloss=0.1323\r\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tloss=0.2793\r\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tloss=0.0935\r\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tloss=0.1272\r\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tloss=0.2473\r\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tloss=0.3396\r\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tloss=0.1521\r\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tloss=0.0909\r\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tloss=0.1455\r\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tloss=0.1976\r\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tloss=0.2174\r\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tloss=0.0634\r\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tloss=0.1372\r\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tloss=0.1149\r\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tloss=0.2346\r\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tloss=0.0631\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl logs distributed-pytorch-job-master-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
